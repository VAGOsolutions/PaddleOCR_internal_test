{
  "timestamp": "2025-10-23T22:05:29.437406",
  "image_path": "test_documents/papers\\nlp_survey_paper.jpg",
  "total_regions": 68,
  "results": [
    {
      "index": 1,
      "text": "ep Learhing for Natural Language Processing:",
      "confidence": 0.9891875982284546,
      "box": [
        [
          129,
          0
        ],
        [
          691,
          0
        ],
        [
          691,
          27
        ],
        [
          129,
          25
        ]
      ]
    },
    {
      "index": 2,
      "text": "A Comprehensive Survey",
      "confidence": 0.9976232051849365,
      "box": [
        [
          220,
          30
        ],
        [
          525,
          36
        ],
        [
          524,
          63
        ],
        [
          219,
          57
        ]
      ]
    },
    {
      "index": 3,
      "text": "John Smith', Jane Doe², Robert Johnson³",
      "confidence": 0.970522940158844,
      "box": [
        [
          221,
          83
        ],
        [
          522,
          88
        ],
        [
          522,
          105
        ],
        [
          220,
          100
        ]
      ]
    },
    {
      "index": 4,
      "text": "'Department of Computer Science, MIT",
      "confidence": 0.9940320253372192,
      "box": [
        [
          160,
          110
        ],
        [
          407,
          112
        ],
        [
          407,
          129
        ],
        [
          160,
          127
        ]
      ]
    },
    {
      "index": 5,
      "text": "Al Research Lab, Stanford University",
      "confidence": 0.9836399555206299,
      "box": [
        [
          159,
          133
        ],
        [
          398,
          136
        ],
        [
          398,
          153
        ],
        [
          159,
          151
        ]
      ]
    },
    {
      "index": 6,
      "text": "Google Research, Mountain View, CA",
      "confidence": 0.9985741972923279,
      "box": [
        [
          160,
          157
        ],
        [
          406,
          159
        ],
        [
          406,
          176
        ],
        [
          160,
          174
        ]
      ]
    },
    {
      "index": 7,
      "text": "Abstract",
      "confidence": 0.9999386072158813,
      "box": [
        [
          38,
          199
        ],
        [
          123,
          201
        ],
        [
          123,
          223
        ],
        [
          37,
          220
        ]
      ]
    },
    {
      "index": 8,
      "text": "Natural Language Processing (NLP) has witnessed remarkable progress",
      "confidence": 0.9919692277908325,
      "box": [
        [
          61,
          227
        ],
        [
          525,
          233
        ],
        [
          525,
          253
        ],
        [
          61,
          248
        ]
      ]
    },
    {
      "index": 9,
      "text": "in recent years, driven by advances in deep learning architectures.",
      "confidence": 0.9855175614356995,
      "box": [
        [
          62,
          249
        ],
        [
          485,
          253
        ],
        [
          485,
          273
        ],
        [
          62,
          269
        ]
      ]
    },
    {
      "index": 10,
      "text": "This paper provides a comprehensive survey of state-of-the-art",
      "confidence": 0.9785851240158081,
      "box": [
        [
          63,
          270
        ],
        [
          461,
          275
        ],
        [
          461,
          293
        ],
        [
          63,
          288
        ]
      ]
    },
    {
      "index": 11,
      "text": "techniques, including transformer models, attention mechanisms, and",
      "confidence": 0.9825713038444519,
      "box": [
        [
          61,
          289
        ],
        [
          503,
          295
        ],
        [
          503,
          316
        ],
        [
          61,
          309
        ]
      ]
    },
    {
      "index": 12,
      "text": "pre-trained language models. We analyze their applications across",
      "confidence": 0.9884340763092041,
      "box": [
        [
          61,
          309
        ],
        [
          489,
          317
        ],
        [
          489,
          337
        ],
        [
          61,
          329
        ]
      ]
    },
    {
      "index": 13,
      "text": "various NLP tasks and discuss future research directions.",
      "confidence": 0.9948579668998718,
      "box": [
        [
          61,
          330
        ],
        [
          424,
          338
        ],
        [
          424,
          355
        ],
        [
          61,
          348
        ]
      ]
    },
    {
      "index": 14,
      "text": "1. Introduction",
      "confidence": 0.9771307110786438,
      "box": [
        [
          38,
          384
        ],
        [
          173,
          387
        ],
        [
          173,
          408
        ],
        [
          37,
          404
        ]
      ]
    },
    {
      "index": 15,
      "text": "Deep learning has revolutionized",
      "confidence": 0.9825443029403687,
      "box": [
        [
          62,
          411
        ],
        [
          279,
          416
        ],
        [
          278,
          433
        ],
        [
          62,
          429
        ]
      ]
    },
    {
      "index": 16,
      "text": "the field of natural language",
      "confidence": 0.998837411403656,
      "box": [
        [
          61,
          429
        ],
        [
          245,
          434
        ],
        [
          245,
          451
        ],
        [
          61,
          446
        ]
      ]
    },
    {
      "index": 17,
      "text": "2. Related Work",
      "confidence": 0.9381600618362427,
      "box": [
        [
          499,
          420
        ],
        [
          639,
          423
        ],
        [
          638,
          443
        ],
        [
          499,
          441
        ]
      ]
    },
    {
      "index": 18,
      "text": "processing. Recent advances in",
      "confidence": 0.9950247406959534,
      "box": [
        [
          61,
          448
        ],
        [
          271,
          451
        ],
        [
          270,
          468
        ],
        [
          61,
          465
        ]
      ]
    },
    {
      "index": 19,
      "text": "Traditional NLP approaches",
      "confidence": 0.985353410243988,
      "box": [
        [
          522,
          447
        ],
        [
          699,
          452
        ],
        [
          698,
          469
        ],
        [
          521,
          464
        ]
      ]
    },
    {
      "index": 20,
      "text": "neural network architectures",
      "confidence": 0.9820990562438965,
      "box": [
        [
          61,
          464
        ],
        [
          248,
          468
        ],
        [
          248,
          485
        ],
        [
          61,
          481
        ]
      ]
    },
    {
      "index": 21,
      "text": "relied heavily on hand-crafted",
      "confidence": 0.9847867488861084,
      "box": [
        [
          520,
          464
        ],
        [
          708,
          469
        ],
        [
          707,
          486
        ],
        [
          519,
          481
        ]
      ]
    },
    {
      "index": 22,
      "text": "have enabled machines to",
      "confidence": 0.999810516834259,
      "box": [
        [
          61,
          482
        ],
        [
          235,
          486
        ],
        [
          235,
          504
        ],
        [
          61,
          499
        ]
      ]
    },
    {
      "index": 23,
      "text": "features and linguistic rules.",
      "confidence": 0.9582163095474243,
      "box": [
        [
          519,
          481
        ],
        [
          695,
          486
        ],
        [
          694,
          504
        ],
        [
          518,
          498
        ]
      ]
    },
    {
      "index": 24,
      "text": "understand and generate human",
      "confidence": 0.9852300882339478,
      "box": [
        [
          61,
          500
        ],
        [
          275,
          506
        ],
        [
          274,
          523
        ],
        [
          61,
          518
        ]
      ]
    },
    {
      "index": 25,
      "text": "The shift to deep learning",
      "confidence": 0.9883666634559631,
      "box": [
        [
          519,
          498
        ],
        [
          676,
          504
        ],
        [
          675,
          521
        ],
        [
          518,
          515
        ]
      ]
    },
    {
      "index": 26,
      "text": "language with unprecedented",
      "confidence": 0.9992389678955078,
      "box": [
        [
          60,
          519
        ],
        [
          257,
          522
        ],
        [
          257,
          539
        ],
        [
          60,
          536
        ]
      ]
    },
    {
      "index": 27,
      "text": "began with word embeddings",
      "confidence": 0.9725608825683594,
      "box": [
        [
          518,
          514
        ],
        [
          702,
          521
        ],
        [
          701,
          541
        ],
        [
          517,
          535
        ]
      ]
    },
    {
      "index": 28,
      "text": "accuracy.",
      "confidence": 0.9998462200164795,
      "box": [
        [
          61,
          538
        ],
        [
          127,
          540
        ],
        [
          127,
          554
        ],
        [
          61,
          552
        ]
      ]
    },
    {
      "index": 29,
      "text": "and recurrent neural networks.",
      "confidence": 0.994644045829773,
      "box": [
        [
          517,
          534
        ],
        [
          706,
          539
        ],
        [
          705,
          556
        ],
        [
          516,
          551
        ]
      ]
    },
    {
      "index": 30,
      "text": "The introduction of attention",
      "confidence": 0.9861356616020203,
      "box": [
        [
          62,
          571
        ],
        [
          241,
          574
        ],
        [
          241,
          590
        ],
        [
          62,
          586
        ]
      ]
    },
    {
      "index": 31,
      "text": "Key milestones include:",
      "confidence": 0.9986835718154907,
      "box": [
        [
          516,
          568
        ],
        [
          662,
          571
        ],
        [
          662,
          590
        ],
        [
          515,
          586
        ]
      ]
    },
    {
      "index": 32,
      "text": "mechanisms and transformer",
      "confidence": 0.9831287860870361,
      "box": [
        [
          61,
          587
        ],
        [
          252,
          592
        ],
        [
          252,
          609
        ],
        [
          61,
          604
        ]
      ]
    },
    {
      "index": 33,
      "text": "•Word2Vec (2013)",
      "confidence": 0.9531766772270203,
      "box": [
        [
          515,
          586
        ],
        [
          633,
          589
        ],
        [
          632,
          606
        ],
        [
          514,
          603
        ]
      ]
    },
    {
      "index": 34,
      "text": "models has been particularly",
      "confidence": 0.9991790056228638,
      "box": [
        [
          60,
          606
        ],
        [
          250,
          609
        ],
        [
          250,
          626
        ],
        [
          60,
          623
        ]
      ]
    },
    {
      "index": 35,
      "text": "• LSTM networks (2014)",
      "confidence": 0.9761819839477539,
      "box": [
        [
          515,
          603
        ],
        [
          661,
          607
        ],
        [
          661,
          625
        ],
        [
          514,
          622
        ]
      ]
    },
    {
      "index": 36,
      "text": "impactful. These innovations",
      "confidence": 0.9846310615539551,
      "box": [
        [
          60,
          623
        ],
        [
          247,
          625
        ],
        [
          247,
          642
        ],
        [
          60,
          640
        ]
      ]
    },
    {
      "index": 37,
      "text": "• Attention mechanism (2015)",
      "confidence": 0.9829787015914917,
      "box": [
        [
          513,
          621
        ],
        [
          693,
          627
        ],
        [
          692,
          645
        ],
        [
          512,
          639
        ]
      ]
    },
    {
      "index": 38,
      "text": "have led to breakthrough",
      "confidence": 0.9981899261474609,
      "box": [
        [
          62,
          643
        ],
        [
          223,
          643
        ],
        [
          223,
          657
        ],
        [
          62,
          657
        ]
      ]
    },
    {
      "index": 39,
      "text": "•Transformer (2017)",
      "confidence": 0.9848506450653076,
      "box": [
        [
          512,
          639
        ],
        [
          640,
          643
        ],
        [
          639,
          660
        ],
        [
          511,
          656
        ]
      ]
    },
    {
      "index": 40,
      "text": "results across multiple NLP",
      "confidence": 0.9994903206825256,
      "box": [
        [
          61,
          658
        ],
        [
          237,
          660
        ],
        [
          237,
          674
        ],
        [
          61,
          672
        ]
      ]
    },
    {
      "index": 41,
      "text": "•BERT (2018)",
      "confidence": 0.9630684852600098,
      "box": [
        [
          511,
          657
        ],
        [
          603,
          659
        ],
        [
          603,
          677
        ],
        [
          510,
          674
        ]
      ]
    },
    {
      "index": 42,
      "text": "benchmarks.",
      "confidence": 0.997366189956665,
      "box": [
        [
          63,
          676
        ],
        [
          147,
          676
        ],
        [
          147,
          691
        ],
        [
          63,
          691
        ]
      ]
    },
    {
      "index": 43,
      "text": "• GPT series (2018-2023)",
      "confidence": 0.9595870971679688,
      "box": [
        [
          510,
          674
        ],
        [
          666,
          679
        ],
        [
          666,
          696
        ],
        [
          509,
          691
        ]
      ]
    },
    {
      "index": 44,
      "text": "3.Methodology",
      "confidence": 0.9902320504188538,
      "box": [
        [
          39,
          716
        ],
        [
          179,
          721
        ],
        [
          179,
          741
        ],
        [
          38,
          736
        ]
      ]
    },
    {
      "index": 45,
      "text": "Our approach combines several",
      "confidence": 0.997490644454956,
      "box": [
        [
          63,
          743
        ],
        [
          265,
          746
        ],
        [
          264,
          763
        ],
        [
          63,
          760
        ]
      ]
    },
    {
      "index": 46,
      "text": "key components:",
      "confidence": 0.9994732141494751,
      "box": [
        [
          62,
          760
        ],
        [
          173,
          763
        ],
        [
          173,
          781
        ],
        [
          62,
          777
        ]
      ]
    },
    {
      "index": 47,
      "text": "4. Results",
      "confidence": 0.9323541522026062,
      "box": [
        [
          485,
          751
        ],
        [
          574,
          754
        ],
        [
          573,
          776
        ],
        [
          484,
          772
        ]
      ]
    },
    {
      "index": 48,
      "text": "Table 1 shows performance",
      "confidence": 0.9831008315086365,
      "box": [
        [
          506,
          777
        ],
        [
          673,
          784
        ],
        [
          673,
          801
        ],
        [
          505,
          794
        ]
      ]
    },
    {
      "index": 49,
      "text": "3.1 Model Architecture",
      "confidence": 0.9783782362937927,
      "box": [
        [
          63,
          794
        ],
        [
          205,
          798
        ],
        [
          204,
          814
        ],
        [
          63,
          810
        ]
      ]
    },
    {
      "index": 50,
      "text": "on standard benchmarks:",
      "confidence": 0.9947949051856995,
      "box": [
        [
          506,
          794
        ],
        [
          660,
          800
        ],
        [
          660,
          817
        ],
        [
          505,
          812
        ]
      ]
    },
    {
      "index": 51,
      "text": "We employ a transformer-based",
      "confidence": 0.9852103590965271,
      "box": [
        [
          62,
          812
        ],
        [
          263,
          815
        ],
        [
          263,
          832
        ],
        [
          62,
          829
        ]
      ]
    },
    {
      "index": 52,
      "text": "encoder-decoder architecture",
      "confidence": 0.9994141459465027,
      "box": [
        [
          62,
          830
        ],
        [
          247,
          833
        ],
        [
          247,
          847
        ],
        [
          62,
          844
        ]
      ]
    },
    {
      "index": 53,
      "text": "Task",
      "confidence": 0.9989101886749268,
      "box": [
        [
          504,
          827
        ],
        [
          541,
          831
        ],
        [
          539,
          849
        ],
        [
          502,
          845
        ]
      ]
    },
    {
      "index": 54,
      "text": "Accuracy",
      "confidence": 0.9998959302902222,
      "box": [
        [
          560,
          830
        ],
        [
          618,
          833
        ],
        [
          617,
          852
        ],
        [
          558,
          848
        ]
      ]
    },
    {
      "index": 55,
      "text": "with multi-head attention.",
      "confidence": 0.999695360660553,
      "box": [
        [
          61,
          846
        ],
        [
          220,
          850
        ],
        [
          219,
          865
        ],
        [
          61,
          860
        ]
      ]
    },
    {
      "index": 56,
      "text": "GLUE",
      "confidence": 0.9997974634170532,
      "box": [
        [
          503,
          861
        ],
        [
          544,
          864
        ],
        [
          543,
          882
        ],
        [
          502,
          879
        ]
      ]
    },
    {
      "index": 57,
      "text": "92.3%",
      "confidence": 0.999886155128479,
      "box": [
        [
          566,
          863
        ],
        [
          606,
          866
        ],
        [
          605,
          883
        ],
        [
          565,
          880
        ]
      ]
    },
    {
      "index": 58,
      "text": "3.2 Training Procedure",
      "confidence": 0.9903202056884766,
      "box": [
        [
          59,
          879
        ],
        [
          207,
          883
        ],
        [
          206,
          899
        ],
        [
          59,
          896
        ]
      ]
    },
    {
      "index": 59,
      "text": "SQuAD",
      "confidence": 0.9941819310188293,
      "box": [
        [
          502,
          879
        ],
        [
          551,
          882
        ],
        [
          550,
          897
        ],
        [
          502,
          895
        ]
      ]
    },
    {
      "index": 60,
      "text": "91.5%",
      "confidence": 0.9998185038566589,
      "box": [
        [
          570,
          880
        ],
        [
          610,
          883
        ],
        [
          609,
          899
        ],
        [
          569,
          897
        ]
      ]
    },
    {
      "index": 61,
      "text": "The model is pre-trained on",
      "confidence": 0.9802021384239197,
      "box": [
        [
          59,
          897
        ],
        [
          233,
          900
        ],
        [
          233,
          916
        ],
        [
          59,
          913
        ]
      ]
    },
    {
      "index": 62,
      "text": "CoNLL",
      "confidence": 0.9984084963798523,
      "box": [
        [
          502,
          898
        ],
        [
          548,
          898
        ],
        [
          548,
          913
        ],
        [
          502,
          913
        ]
      ]
    },
    {
      "index": 63,
      "text": "94.2%",
      "confidence": 0.9999274015426636,
      "box": [
        [
          568,
          900
        ],
        [
          608,
          900
        ],
        [
          608,
          915
        ],
        [
          568,
          915
        ]
      ]
    },
    {
      "index": 64,
      "text": "large text corpora using",
      "confidence": 0.9890961050987244,
      "box": [
        [
          57,
          914
        ],
        [
          209,
          917
        ],
        [
          208,
          933
        ],
        [
          57,
          930
        ]
      ]
    },
    {
      "index": 65,
      "text": "masked language modeling.",
      "confidence": 0.9846791625022888,
      "box": [
        [
          59,
          931
        ],
        [
          237,
          934
        ],
        [
          237,
          948
        ],
        [
          59,
          945
        ]
      ]
    },
    {
      "index": 66,
      "text": "Our model achieves state-of-",
      "confidence": 0.9985560774803162,
      "box": [
        [
          499,
          930
        ],
        [
          671,
          933
        ],
        [
          671,
          950
        ],
        [
          499,
          947
        ]
      ]
    },
    {
      "index": 67,
      "text": "the-art results, outperforming",
      "confidence": 0.9944743514060974,
      "box": [
        [
          498,
          947
        ],
        [
          668,
          952
        ],
        [
          668,
          969
        ],
        [
          498,
          964
        ]
      ]
    },
    {
      "index": 68,
      "text": "previous approaches by 2-3%.",
      "confidence": 0.9724341630935669,
      "box": [
        [
          498,
          965
        ],
        [
          680,
          969
        ],
        [
          680,
          985
        ],
        [
          498,
          982
        ]
      ]
    }
  ]
}